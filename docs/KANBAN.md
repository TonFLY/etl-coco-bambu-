# Kanban - Desafio Engenharia de Dados

## Objetivo
Este documento organiza as tarefas do desafio de engenharia de dados utilizando o m√©todo Kanban, separando as atividades em **A Fazer**, **Em Progresso**, e **Conclu√≠do**.

---

## üóÇÔ∏è Colunas do Kanban

### üìã A Fazer
- [ ] Analisar os requisitos do desafio.
- [ ] Estruturar a modelagem das tabelas no PostgreSQL.
- [ ] Criar scripts para ingest√£o de dados no banco.
- [ ] Configurar o ambiente (AWS, PostgreSQL e Python).
- [ ] Criar estrutura de pastas no S3 para armazenar os dados das APIs.
- [ ] Documentar toda a abordagem no README.md.
- [ ] Preparar o reposit√≥rio no GitHub para entrega.

### üîÑ Em Progresso
- [ ] Implementar o pipeline ETL din√¢mico e resiliente.
- [ ] Testar com JSONs diferentes para validar robustez do pipeline.
- [ ] Configurar logs para erros no processamento e armazen√°-los no S3.

### ‚úÖ Conclu√≠do
- [x] Configura√ß√£o do PostgreSQL e cria√ß√£o do banco de dados.
- [x] Desenvolvimento dos scripts SQL para cria√ß√£o das tabelas.
- [x] Implementa√ß√£o inicial do pipeline ETL.
- [x] Configura√ß√£o do ambiente Python com depend√™ncias (`boto3`, `psycopg2`, etc.).
- [x] Configura√ß√£o do bucket S3 para ingest√£o e organiza√ß√£o dos dados.
- [x] Adi√ß√£o de valida√ß√µes din√¢micas para lidar com mudan√ßas no JSON.
- [x] Teste com m√∫ltiplos cen√°rios de JSON (campos ausentes, renomea√ß√µes, etc.).

---

## üìä Status Atual
- O pipeline ETL j√° est√° implementado e funcionando com JSONs din√¢micos.
- Dados s√£o ingeridos no banco de dados PostgreSQL, e logs de erros s√£o armazenados no S3.
- Testes foram realizados para cen√°rios comuns e edge cases.

---

## üîÑ Pr√≥ximos Passos
- Finalizar a documenta√ß√£o detalhada no README.md.
- Realizar testes finais com todos os endpoints e cen√°rios fornecidos.
- Subir o reposit√≥rio no GitHub e compartilhar o link para avalia√ß√£o.

---

## üí° Melhorias Futuras
- [ ] Integrar o pipeline com ferramentas de orquestra√ß√£o como Apache Airflow.
- [ ] Implementar gera√ß√£o autom√°tica de colunas no banco em caso de mudan√ßas no JSON.
- [ ] Adicionar m√©tricas de performance e monitoramento ao pipeline.
- [ ] Configurar pipelines para outras camadas do data lake (transformadas, anal√≠ticas).

---

**Organiza√ß√£o e Execu√ß√£o por:** Wellington Marques
